
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Detecting Cars in a Video of Traffic</title><meta name="generator" content="MATLAB 7.11"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2010-06-29"><meta name="DC.source" content="ipextraffic.m"><link rel="stylesheet" type="text/css" href="../../../matlab/demos/private/style.css"></head><body><div class="header"><div class="left"><a href="matlab:edit ipextraffic">Open ipextraffic.m in the Editor</a></div><div class="right"><a href="matlab:echodemo ipextraffic">Run in the Command Window</a></div></div><div class="content"><h1>Detecting Cars in a Video of Traffic</h1><!--introduction--><p>You can use Image Processing Toolbox&#8482; to visualize and analyze videos or image sequences. This example uses <tt>mmreader</tt> (MATLAB&reg;), <tt>implay</tt>, and other Image Processing Toolbox functions to detect light-colored cars in a video of traffic. Note that <tt>mmreader</tt> has platform-specific capabilities and may not be able to read the supplied Motion JPEG2000 video on some platforms. See <a href="matlab:doc('mmreader')">the documentation</a> for <tt>mmreader</tt> for information on which formats are supported on your platform.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Step 1: Access Video with MMREADER</a></li><li><a href="#3">Step 2: Explore Video with IMPLAY</a></li><li><a href="#4">Step 3: Develop Your Algorithm</a></li><li><a href="#7">Step 4: Apply the Algorithm to the Video</a></li><li><a href="#8">Step 5: Visualize Results</a></li></ul></div><h2>Step 1: Access Video with MMREADER<a name="1"></a></h2><p>The <tt>mmreader</tt> function constructs a multimedia reader object that can read video data from a multimedia file.  See <a href="matlab:doc('mmreader')">the documentation</a> for <tt>mmreader</tt> for information on which formats are supported on your platform.</p><p>Use <tt>mmreader</tt> to access the video and get basic information about it.</p><pre class="codeinput">trafficObj = mmreader(<span class="string">'traffic.mj2'</span>)
</pre><pre class="codeoutput">
Summary of Multimedia Reader Object for 'traffic.mj2'.

  Video Parameters:  15.00 frames per second, RGB24 160x120.
                     120 total video frames available.

</pre><p>The get method provides more information on the video such as its duration in seconds.</p><pre class="codeinput">get(trafficObj)
</pre><pre class="codeoutput">  General Settings:
    Duration = 8
    Name = traffic.mj2
    Path = B:\matlab\toolbox\images\imdemos
    Tag = 
    Type = VideoReader
    UserData = []

  Video Settings:
    BitsPerPixel = 24
    FrameRate = 15
    Height = 120
    NumberOfFrames = 120
    VideoFormat = RGB24
    Width = 160

</pre><h2>Step 2: Explore Video with IMPLAY<a name="3"></a></h2><p>Explore the video in <tt>implay</tt>.</p><pre class="codeinput">implay(<span class="string">'traffic.mj2'</span>);
</pre><img vspace="5" hspace="5" src="ipextraffic_01.png" alt=""> <h2>Step 3: Develop Your Algorithm<a name="4"></a></h2><p>When working with video data, it can be helpful to select a representative frame from the video and develop your algorithm on that frame. Then, this algorithm can be applied to the processing of all the frames in the video.</p><p>For this car-tagging application, examine a frame that includes both light-colored and dark-colored cars. When an image has many structures, like the traffic video frames, it is useful to simplify the image as much as possible before trying to detect an object of interest. One way to do this for the car tagging application is to suppress all objects in the image that are not light-colored cars (dark-colored cars, lanes, grass, etc.). Typically, it takes a combination of techniques to remove these extraneous objects.</p><p>One way to remove the dark-colored cars from the video frames is to use the <tt>imextendedmax</tt> function. This function returns a binary image that identifies regions with intensity values above a specified threshold, called regional maxima. All other objects in the image with pixel values below this threshold become the background. To eliminate the dark-colored cars, determine the average pixel value for these objects in the image. (Use <tt>rgb2gray</tt> to convert the original video from RGB to grayscale.) You can use the pixel region tool in <tt>implay</tt> to view pixel values. Specify the average pixel value (or a value slightly higher) as the threshold when you call <tt>imextendedmax</tt>. For this demo, set the value to 50.</p><pre class="codeinput">darkCarValue = 50;
darkCar = rgb2gray(read(trafficObj,71));
noDarkCar = imextendedmax(darkCar, darkCarValue);
imshow(darkCar)
figure, imshow(noDarkCar)
</pre><img vspace="5" hspace="5" src="ipextraffic_02.png" alt=""> <img vspace="5" hspace="5" src="ipextraffic_03.png" alt=""> <p>In the processed image, note how most of the dark-colored car objects are removed but many other extraneous objects remain, particularly the lane-markings. The regional maxima processing will not remove the lane markings because their pixel values are above the threshold. To remove these objects, you can use the morphological function <tt>imopen</tt>. This function uses morphological processing to remove small objects from a binary image while preserving large objects. When using morphological processing, you must decide on the size and shape of the structuring element used in the operation. Because the lane-markings are long and thin objects, use a disk-shaped structuring element with radius corresponding to the width of the lane markings. You can use the pixel region tool in <tt>implay</tt> to estimate the width of these objects. For this demo, set the value to 2.</p><pre class="codeinput">sedisk = strel(<span class="string">'disk'</span>,2);
noSmallStructures = imopen(noDarkCar, sedisk);
imshow(noSmallStructures)
</pre><img vspace="5" hspace="5" src="ipextraffic_04.png" alt=""> <p>To complete the algorithm, use <tt>regionprops</tt> to find the centroid of the objects in <tt>noSmallStructures</tt> (should just be the light-colored cars). Use this information to position the tag on the light-colored cars in the original video.</p><h2>Step 4: Apply the Algorithm to the Video<a name="7"></a></h2><p>The car-tagging application processes the video one frame at a time in a loop. (Because a typical video contains a large number of frames, it would take a lot of memory to read and process all the frames at once.)</p><p>A small video (like the one in this example) could be processed at once, and there are many functions that provide this capability. For more information, see <a href="http://www.mathworks.com/access/helpdesk/help/toolbox/images/f14-17682.html">the Documentation</a>.</p><p>For faster processing, preallocate the memory used to store the processed video.</p><pre class="codeinput">nframes = get(trafficObj, <span class="string">'NumberOfFrames'</span>);
I = read(trafficObj, 1);
taggedCars = zeros([size(I,1) size(I,2) 3 nframes], class(I));

<span class="keyword">for</span> k = 1 : nframes
    singleFrame = read(trafficObj, k);

    <span class="comment">% Convert to grayscale to do morphological processing.</span>
    I = rgb2gray(singleFrame);

    <span class="comment">% Remove dark cars.</span>
    noDarkCars = imextendedmax(I, darkCarValue);

    <span class="comment">% Remove lane markings and other non-disk shaped structures.</span>
    noSmallStructures = imopen(noDarkCars, sedisk);

    <span class="comment">% Remove small structures.</span>
    noSmallStructures = bwareaopen(noSmallStructures, 150);

    <span class="comment">% Get the area and centroid of each remaining object in the frame. The</span>
    <span class="comment">% object with the largest area is the light-colored car.  Create a copy</span>
    <span class="comment">% of the original frame and tag the car by changing the centroid pixel</span>
    <span class="comment">% value to red.</span>
    taggedCars(:,:,:,k) = singleFrame;

    stats = regionprops(noSmallStructures, {<span class="string">'Centroid'</span>,<span class="string">'Area'</span>});
    <span class="keyword">if</span> ~isempty([stats.Area])
        areaArray = [stats.Area];
        [junk,idx] = max(areaArray);
        c = stats(idx).Centroid;
        c = floor(fliplr(c));
        width = 2;
        row = c(1)-width:c(1)+width;
        col = c(2)-width:c(2)+width;
        taggedCars(row,col,1,k) = 255;
        taggedCars(row,col,2,k) = 0;
        taggedCars(row,col,3,k) = 0;
    <span class="keyword">end</span>
<span class="keyword">end</span>
</pre><h2>Step 5: Visualize Results<a name="8"></a></h2><p>Get the frame rate of the original video and use it to see <tt>taggedCars</tt> in <tt>implay</tt>.</p><pre class="codeinput">frameRate = get(trafficObj,<span class="string">'FrameRate'</span>);
implay(taggedCars,frameRate);
</pre><img vspace="5" hspace="5" src="ipextraffic_05.png" alt=""> <p class="footer">Copyright 2007-2010 The MathWorks, Inc.<br>
          Published with MATLAB&reg; 7.11</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!--
##### SOURCE BEGIN #####
%% Detecting Cars in a Video of Traffic
% You can use Image Processing Toolbox(TM) to visualize and analyze videos
% or image sequences. This example uses |mmreader| (MATLAB(R)), |implay|,
% and other Image Processing Toolbox functions to detect light-colored cars
% in a video of traffic. Note that |mmreader| has platform-specific
% capabilities and may not be able to read the supplied Motion JPEG2000
% video on some platforms. See <matlab:doc('mmreader') the documentation>
% for |mmreader| for information on which formats are supported on your
% platform.

% Copyright 2007-2010 The MathWorks, Inc.

%% Step 1: Access Video with MMREADER
% The |mmreader| function constructs a multimedia reader object that can
% read video data from a multimedia file.  See <matlab:doc('mmreader') the
% documentation> for |mmreader| for information on which formats are
% supported on your platform.
%   
% Use |mmreader| to access the video and get basic information about it. 
trafficObj = mmreader('traffic.mj2')

%%
% The get method provides more information on the video such as its
% duration in seconds.
get(trafficObj)

%% Step 2: Explore Video with IMPLAY
% Explore the video in |implay|. 

implay('traffic.mj2');

%% Step 3: Develop Your Algorithm
% When working with video data, it can be helpful to select a
% representative frame from the video and develop your algorithm on that
% frame. Then, this algorithm can be applied to the processing of all the
% frames in the video.
%
% For this car-tagging application, examine a frame that includes both
% light-colored and dark-colored cars. When an image has many structures,
% like the traffic video frames, it is useful to simplify the image as much
% as possible before trying to detect an object of interest. One way to do
% this for the car tagging application is to suppress all objects in the
% image that are not light-colored cars (dark-colored cars, lanes, grass,
% etc.). Typically, it takes a combination of techniques to remove these
% extraneous objects. 
%
% One way to remove the dark-colored cars from the video frames is to use
% the |imextendedmax| function. This function returns a binary image that
% identifies regions with intensity values above a specified threshold,
% called regional maxima. All other objects in the image with pixel values
% below this threshold become the background. To eliminate the dark-colored
% cars, determine the average pixel value for these objects in the image.
% (Use |rgb2gray| to convert the original video from RGB to grayscale.) You
% can use the pixel region tool in |implay| to view pixel values. Specify the
% average pixel value (or a value slightly higher) as the threshold when
% you call |imextendedmax|. For this demo, set the value to 50.

darkCarValue = 50;
darkCar = rgb2gray(read(trafficObj,71));
noDarkCar = imextendedmax(darkCar, darkCarValue);
imshow(darkCar)
figure, imshow(noDarkCar)

%%
% In the processed image, note how most of the dark-colored car objects are
% removed but many other extraneous objects remain, particularly the
% lane-markings. The regional maxima processing will not remove the lane
% markings because their pixel values are above the threshold. To remove
% these objects, you can use the morphological function |imopen|. This
% function uses morphological processing to remove small objects from a
% binary image while preserving large objects. When using morphological
% processing, you must decide on the size and shape of the structuring
% element used in the operation. Because the lane-markings are long and
% thin objects, use a disk-shaped structuring element with radius
% corresponding to the width of the lane markings. You can use the pixel
% region tool in |implay| to estimate the width of these objects. For this
% demo, set the value to 2. 

sedisk = strel('disk',2);
noSmallStructures = imopen(noDarkCar, sedisk);
imshow(noSmallStructures)

%%
% To complete the algorithm, use |regionprops| to find the centroid of the
% objects in |noSmallStructures| (should just be the light-colored cars).
% Use this information to position the tag on the light-colored cars in the
% original video. 

%% Step 4: Apply the Algorithm to the Video
% The car-tagging application processes the video one frame at a time in a
% loop. (Because a typical video contains a large number of frames, it
% would take a lot of memory to read and process all the frames at once.)
%
% A small video (like the one in this example) could be processed at once,
% and there are many functions that provide this capability. For more
% information, see <http://www.mathworks.com/access/helpdesk/help/toolbox/images/f14-17682.html the Documentation>.
%
% For faster processing, preallocate the memory used to store the processed
% video.

nframes = get(trafficObj, 'NumberOfFrames');
I = read(trafficObj, 1);
taggedCars = zeros([size(I,1) size(I,2) 3 nframes], class(I));

for k = 1 : nframes
    singleFrame = read(trafficObj, k);
    
    % Convert to grayscale to do morphological processing.
    I = rgb2gray(singleFrame);
    
    % Remove dark cars.
    noDarkCars = imextendedmax(I, darkCarValue); 
    
    % Remove lane markings and other non-disk shaped structures.
    noSmallStructures = imopen(noDarkCars, sedisk);

    % Remove small structures.
    noSmallStructures = bwareaopen(noSmallStructures, 150);
   
    % Get the area and centroid of each remaining object in the frame. The
    % object with the largest area is the light-colored car.  Create a copy
    % of the original frame and tag the car by changing the centroid pixel
    % value to red.
    taggedCars(:,:,:,k) = singleFrame;
   
    stats = regionprops(noSmallStructures, {'Centroid','Area'});
    if ~isempty([stats.Area])
        areaArray = [stats.Area];
        [junk,idx] = max(areaArray);
        c = stats(idx).Centroid;
        c = floor(fliplr(c));
        width = 2;
        row = c(1)-width:c(1)+width;
        col = c(2)-width:c(2)+width;
        taggedCars(row,col,1,k) = 255;
        taggedCars(row,col,2,k) = 0;
        taggedCars(row,col,3,k) = 0;
    end
end

%% Step 5: Visualize Results
% Get the frame rate of the original video and use it to
% see |taggedCars| in |implay|. 

frameRate = get(trafficObj,'FrameRate');
implay(taggedCars,frameRate);

displayEndOfDemoMessage(mfilename)

##### SOURCE END #####
--></body></html>