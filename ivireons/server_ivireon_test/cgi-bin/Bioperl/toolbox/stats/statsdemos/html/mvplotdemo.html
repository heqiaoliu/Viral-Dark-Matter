
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Visualizing Multivariate Data</title><meta name="generator" content="MATLAB 7.11"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2010-06-29"><meta name="DC.source" content="mvplotdemo.m"><link rel="stylesheet" type="text/css" href="../../../matlab/demos/private/style.css"></head><body><div class="header"><div class="left"><a href="matlab:edit mvplotdemo">Open mvplotdemo.m in the Editor</a></div><div class="right"><a href="matlab:echodemo mvplotdemo">Run in the Command Window</a></div></div><div class="content"><h1>Visualizing Multivariate Data</h1><!--introduction--><p>Many statistical analyses involve only two variables: a predictor variable and a response variable.  Such data are easy to visualize using 2D scatter plots, bivariate histograms, boxplots, etc.  It's also possible to visualize trivariate data with 3D scatter plots, or 2D scatter plots with a third variable encoded with, for example color. However, many datasets involve a larger number of variables, making direct visualization more difficult.  This demo explores some of the ways to visualize high-dimensional data in MATLAB&reg;, using the Statistics Toolbox&#8482;.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#2">Scatterplot Matrices</a></li><li><a href="#4">Parallel Coordinates Plots</a></li><li><a href="#7">Andrews Plots</a></li><li><a href="#10">Glyph Plots</a></li><li><a href="#12">Glyph Plots and Multidimensional Scaling</a></li></ul></div><p>In this demo, we'll use the <tt>carbig</tt> dataset, a dataset that contains various measured variables for about 400 automobiles from the 1970's and 1980's.  We'll illustrate multivariate visualization using the values for fuel efficiency (in miles per gallon, MPG), acceleration (time from 0-60MPH in sec), engine displacement (in cubic inches), weight, and horsepower.  We'll use the number of cylinders to group observations.</p><pre class="codeinput">load <span class="string">carbig</span>
X = [MPG,Acceleration,Displacement,Weight,Horsepower];
varNames = {<span class="string">'MPG'</span>; <span class="string">'Acceleration'</span>; <span class="string">'Displacement'</span>; <span class="string">'Weight'</span>; <span class="string">'Horsepower'</span>};
</pre><h2>Scatterplot Matrices<a name="2"></a></h2><p>Viewing slices through lower dimensional subspaces is one way to partially work around the limitation of two or three dimensions.  For example, we can use the <tt>gplotmatrix</tt> function to display an array of all the bivariate scatterplots between our five variables, along with a univariate histogram for each variable.</p><pre class="codeinput">figure
gplotmatrix(X,[],Cylinders,[<span class="string">'c'</span> <span class="string">'b'</span> <span class="string">'m'</span> <span class="string">'g'</span> <span class="string">'r'</span>],[],[],false);
text([.08 .24 .43 .66 .83], repmat(-.1,1,5), varNames, <span class="string">'FontSize'</span>,8);
text(repmat(-.12,1,5), [.86 .62 .41 .25 .02], varNames, <span class="string">'FontSize'</span>,8, <span class="string">'Rotation'</span>,90);
</pre><img vspace="5" hspace="5" src="mvplotdemo_01.png" alt=""> <p>The points in each scatterplot are color-coded by the number of cylinders: blue for 4 cylinders, green for 6, and red for 8.  There is also a handful of 5 cylinder cars, and rotary-engined cars are listed as having 3 cylinders.  This array of plots makes it easy to pick out patterns in the relationships between pairs of variables.  However, there may be important patterns in higher dimensions, and those are not easy to recognize in this plot.</p><h2>Parallel Coordinates Plots<a name="4"></a></h2><p>The scatterplot matrix only displays bivariate relationships.  However, there are other alternatives that display all the variables together, allowing you to investigate higher-dimensional relationships among variables.  The most straight-forward multivariate plot is the parallel coordinates plot.  In this plot, the coordinate axes are all laid out horizontally, instead of using orthogonal axes as in the usual Cartesian graph.  Each observation is represented in the plot as a series of connected line segments.  For example, we can make a plot of all the cars with 4, 6, or 8 cylinders, and color observations by group.</p><pre class="codeinput">Cyl468 = ismember(Cylinders,[4 6 8]);
parallelcoords(X(Cyl468,:), <span class="string">'group'</span>,Cylinders(Cyl468), <span class="keyword">...</span>
               <span class="string">'standardize'</span>,<span class="string">'on'</span>, <span class="string">'labels'</span>,varNames)
</pre><img vspace="5" hspace="5" src="mvplotdemo_02.png" alt=""> <p>The horizontal direction in this plot represents the coordinate axes, and the vertical direction represents the data.  Each observation consists of measurements on five variables, and each measurement is represented as the height at which the corresponding line crosses each coordinate axis. Because the five variables have widely different ranges, this plot was made with standardized values, where each variable has been standardized to have zero mean and unit variance.  With the color coding, the graph shows, for example, that 8 cylinder cars typically have low values for MPG and acceleration, and high values for displacement, weight, and horsepower.</p><p>Even with color coding by group, a parallel coordinates plot with a large number of observations can be difficult to read.  We can also make a parallel coordinates plot where only the median and quartiles (25% and 75% points) for each group are shown.  This makes the typical differences and similarities among groups easier to distinguish.  On the other hand, it may be the outliers for each group that are most interesting, and this plot does not show them at all.</p><pre class="codeinput">parallelcoords(X(Cyl468,:), <span class="string">'group'</span>,Cylinders(Cyl468), <span class="keyword">...</span>
               <span class="string">'standardize'</span>,<span class="string">'on'</span>, <span class="string">'labels'</span>,varNames, <span class="string">'quantile'</span>,.25)
</pre><img vspace="5" hspace="5" src="mvplotdemo_03.png" alt=""> <h2>Andrews Plots<a name="7"></a></h2><p>Another similar type of multivariate visualization is the Andrews plot. This plot represents each observation as a smooth function over the interval [0,1].</p><pre class="codeinput">andrewsplot(X(Cyl468,:), <span class="string">'group'</span>,Cylinders(Cyl468), <span class="string">'standardize'</span>,<span class="string">'on'</span>)
</pre><img vspace="5" hspace="5" src="mvplotdemo_04.png" alt=""> <p>Each function is a Fourier series, with coefficients equal to the corresponding observation's values.  In this example, the series has five terms: a constant, two sine terms with periods 1 and 1/2, and two similar cosine terms.  Effects on the functions' shapes due to the three leading terms are the most apparent in an Andrews plot, so patterns in the first three variables tend to be the ones most easily recognized.</p><p>There's a distinct difference between groups at t = 0, indicating that the first variable, MPG, is one of the distinguishing features between 4, 6, and 8 cylinder cars.  More interesting is the difference between the three groups at around t = 1/3.  Plugging this value into the formula for the Andrews plot functions, we get a set of coefficients that define a linear combination of the variables that distinguishes between groups.</p><pre class="codeinput">t1 = 1/3;
[1/sqrt(2) sin(2*pi*t1) cos(2*pi*t1) sin(4*pi*t1) cos(4*pi*t1)]
</pre><pre class="codeoutput">
ans =

    0.7071    0.8660   -0.5000   -0.8660   -0.5000

</pre><p>From these coefficients, we can see that one way to distinguish 4 cylinder cars from 8 cylinder cars is that the former have higher values of MPG and acceleration, and lower values of displacement, horsepower, and particularly weight, while the latter have the opposite.  That's the same conclusion we drew from the parallel coordinates plot.</p><h2>Glyph Plots<a name="10"></a></h2><p>Another way to visualize multivariate data is to use "glyphs" to represent the dimensions.  The function <tt>glyphplot</tt> supports two types of glyphs:  stars, and Chernoff faces.  For example, here is a star plot of the first 9 models in the car data.  Each spoke in a star represents one variable, and the spoke length is proportional to the value of that variable for that observation.</p><pre class="codeinput">h = glyphplot(X(1:9,:), <span class="string">'glyph'</span>,<span class="string">'star'</span>, <span class="string">'varLabels'</span>,varNames, <span class="string">'obslabels'</span>,Model(1:9,:));
set(h(:,3),<span class="string">'FontSize'</span>,8);
</pre><img vspace="5" hspace="5" src="mvplotdemo_05.png" alt=""> <p>In a live MATLAB figure window, this plot would allow interactive exploration of the data values, using data cursors.  For example, clicking on the right-hand point of the star for the Ford Torino would show that it has an MPG value of 17.</p><h2>Glyph Plots and Multidimensional Scaling<a name="12"></a></h2><p>Plotting stars on a grid, with no particular order, can lead to a figure that is confusing, because adjacent stars can end up quite different-looking.  Thus, there may be no smooth pattern for the eye to catch.  It's often useful to combine multidimensional scaling (MDS) with a glyph plot.  To illustrate, we'll first select all cars from 1977, and use the <tt>zscore</tt> function to standardize each of the five variables to have zero mean and unit variance.  Then we'll compute the Euclidean distances among those standardized observations as a measure of dissimilarity.  This choice might be too simplistic in a real application, but serves here for purposes of illustration.</p><pre class="codeinput">models77 = find((Model_Year==77));
dissimilarity = pdist(zscore(X(models77,:)));
</pre><p>Finally, we use <tt>mdscale</tt> to create a set of locations in two dimensions whose interpoint distances approximate the dissimilarities among the original high-dimensional data, and plot the glyphs using those locations.  The distances in this 2D plot may only roughly reproduce the data, but for this type of plot, that's good enough.</p><pre class="codeinput">Y = mdscale(dissimilarity,2);
glyphplot(X(models77,:), <span class="string">'glyph'</span>,<span class="string">'star'</span>, <span class="string">'centers'</span>,Y, <span class="keyword">...</span>
          <span class="string">'varLabels'</span>,varNames, <span class="string">'obslabels'</span>,Model(models77,:), <span class="string">'radius'</span>,.5);
title(<span class="string">'1977 Model Year'</span>);
</pre><img vspace="5" hspace="5" src="mvplotdemo_06.png" alt=""> <p>In this plot, we've used MDS as dimension reduction method, to create a 2D plot.  Normally that would mean a loss of information, but by plotting the glyphs, we have incorporated all of the high-dimensional information in the data.  The purpose of using MDS is to impose some regularity to the variation in the data, so that patterns among the glyphs are easier to see.</p><p>Just as with the previous plot, interactive exploration would be possible in a live figure window.</p><p>Another type of glyph is the Chernoff face.  This glyph encodes the data values for each observation into facial features, such as the size of the face, the shape of the face, position of the eyes, etc.</p><pre class="codeinput">glyphplot(X(models77,:), <span class="string">'glyph'</span>,<span class="string">'face'</span>, <span class="string">'centers'</span>,Y, <span class="keyword">...</span>
          <span class="string">'varLabels'</span>,varNames, <span class="string">'obslabels'</span>,Model(models77,:));
title(<span class="string">'1977 Model Year'</span>);
</pre><img vspace="5" hspace="5" src="mvplotdemo_07.png" alt=""> <p>Here, the two most apparent features, face size and relative forehead/jaw size, encode MPG and acceleration, while the forehead and jaw shape encode displacement and weight.  Width between eyes encodes horsepower. It's notable that there are few faces with wide foreheads and narrow jaws, or vice-versa, indicating positive linear correlation between the variables displacement and weight.  That's also what we saw in the scatterplot matrix.</p><p>The correspondence of features to variables determines what relationships are easiest to see, and <tt>glyphplot</tt> allows the choice to be changed easily.</p><pre class="codeinput">close
</pre><p class="footer">Copyright 2004-2009 The MathWorks, Inc.<br>
          Published with MATLAB&reg; 7.11</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!--
##### SOURCE BEGIN #####
%% Visualizing Multivariate Data
% Many statistical analyses involve only two variables: a predictor
% variable and a response variable.  Such data are easy to visualize using
% 2D scatter plots, bivariate histograms, boxplots, etc.  It's also
% possible to visualize trivariate data with 3D scatter plots, or 2D
% scatter plots with a third variable encoded with, for example color.
% However, many datasets involve a larger number of variables, making
% direct visualization more difficult.  This demo explores some of the ways
% to visualize high-dimensional data in MATLAB(R), using the Statistics Toolbox(TM).

%   Copyright 2004-2009 The MathWorks, Inc.
%   $Revision: 1.1.8.1 $  $Date: 2010/03/16 00:31:25 $

%%
% In this demo, we'll use the |carbig| dataset, a dataset that contains
% various measured variables for about 400 automobiles from the 1970's and
% 1980's.  We'll illustrate multivariate visualization using the values for
% fuel efficiency (in miles per gallon, MPG), acceleration (time from
% 0-60MPH in sec), engine displacement (in cubic inches), weight, and
% horsepower.  We'll use the number of cylinders to group observations.
load carbig
X = [MPG,Acceleration,Displacement,Weight,Horsepower];
varNames = {'MPG'; 'Acceleration'; 'Displacement'; 'Weight'; 'Horsepower'};

%% Scatterplot Matrices
% Viewing slices through lower dimensional subspaces is one way to
% partially work around the limitation of two or three dimensions.  For
% example, we can use the |gplotmatrix| function to display an array of all
% the bivariate scatterplots between our five variables, along with a
% univariate histogram for each variable.
figure
gplotmatrix(X,[],Cylinders,['c' 'b' 'm' 'g' 'r'],[],[],false);
text([.08 .24 .43 .66 .83], repmat(-.1,1,5), varNames, 'FontSize',8);
text(repmat(-.12,1,5), [.86 .62 .41 .25 .02], varNames, 'FontSize',8, 'Rotation',90);

%%
% The points in each scatterplot are color-coded by the number of
% cylinders: blue for 4 cylinders, green for 6, and red for 8.  There is
% also a handful of 5 cylinder cars, and rotary-engined cars are listed as
% having 3 cylinders.  This array of plots makes it easy to pick out
% patterns in the relationships between pairs of variables.  However, there
% may be important patterns in higher dimensions, and those are not easy
% to recognize in this plot.


%% Parallel Coordinates Plots
% The scatterplot matrix only displays bivariate relationships.  However,
% there are other alternatives that display all the variables together,
% allowing you to investigate higher-dimensional relationships among
% variables.  The most straight-forward multivariate plot is the
% parallel coordinates plot.  In this plot, the coordinate axes are all
% laid out horizontally, instead of using orthogonal axes as in the usual
% Cartesian graph.  Each observation is represented in the plot as a series
% of connected line segments.  For example, we can make a plot of all the
% cars with 4, 6, or 8 cylinders, and color observations by group.
Cyl468 = ismember(Cylinders,[4 6 8]);
parallelcoords(X(Cyl468,:), 'group',Cylinders(Cyl468), ...
               'standardize','on', 'labels',varNames)

%%
% The horizontal direction in this plot represents the coordinate axes, and
% the vertical direction represents the data.  Each observation consists of
% measurements on five variables, and each measurement is represented as
% the height at which the corresponding line crosses each coordinate axis.
% Because the five variables have widely different ranges, this plot was
% made with standardized values, where each variable has been standardized
% to have zero mean and unit variance.  With the color coding, the graph
% shows, for example, that 8 cylinder cars typically have low values for
% MPG and acceleration, and high values for displacement, weight, and
% horsepower.

%%
% Even with color coding by group, a parallel coordinates plot with a large
% number of observations can be difficult to read.  We can also make a
% parallel coordinates plot where only the median and quartiles (25% and 75%
% points) for each group are shown.  This makes the typical differences and
% similarities among groups easier to distinguish.  On the other hand, it
% may be the outliers for each group that are most interesting, and this
% plot does not show them at all.
parallelcoords(X(Cyl468,:), 'group',Cylinders(Cyl468), ...
               'standardize','on', 'labels',varNames, 'quantile',.25)


%% Andrews Plots
% Another similar type of multivariate visualization is the Andrews plot.
% This plot represents each observation as a smooth function over the
% interval [0,1].
andrewsplot(X(Cyl468,:), 'group',Cylinders(Cyl468), 'standardize','on')

%%
% Each function is a Fourier series, with coefficients equal to the
% corresponding observation's values.  In this example, the series has five
% terms: a constant, two sine terms with periods 1 and 1/2, and two similar
% cosine terms.  Effects on the functions' shapes due to the three leading
% terms are the most apparent in an Andrews plot, so patterns in the first
% three variables tend to be the ones most easily recognized.
%
% There's a distinct difference between groups at t = 0, indicating that
% the first variable, MPG, is one of the distinguishing features between 4,
% 6, and 8 cylinder cars.  More interesting is the difference between the
% three groups at around t = 1/3.  Plugging this value into the formula
% for the Andrews plot functions, we get a set of coefficients that define a
% linear combination of the variables that distinguishes between groups.
t1 = 1/3;
[1/sqrt(2) sin(2*pi*t1) cos(2*pi*t1) sin(4*pi*t1) cos(4*pi*t1)]

%%
% From these coefficients, we can see that one way to distinguish 4
% cylinder cars from 8 cylinder cars is that the former have higher values
% of MPG and acceleration, and lower values of displacement, horsepower,
% and particularly weight, while the latter have the opposite.  That's the
% same conclusion we drew from the parallel coordinates plot.


%% Glyph Plots
% Another way to visualize multivariate data is to use "glyphs" to
% represent the dimensions.  The function |glyphplot| supports two types of
% glyphs:  stars, and Chernoff faces.  For example, here is a star plot of
% the first 9 models in the car data.  Each spoke in a star represents one
% variable, and the spoke length is proportional to the value of that
% variable for that observation.
h = glyphplot(X(1:9,:), 'glyph','star', 'varLabels',varNames, 'obslabels',Model(1:9,:));
set(h(:,3),'FontSize',8);

%%
% In a live MATLAB figure window, this plot would allow interactive
% exploration of the data values, using data cursors.  For example,
% clicking on the right-hand point of the star for the Ford Torino would
% show that it has an MPG value of 17.


%% Glyph Plots and Multidimensional Scaling
% Plotting stars on a grid, with no particular order, can lead to a figure
% that is confusing, because adjacent stars can end up quite
% different-looking.  Thus, there may be no smooth pattern for the eye to
% catch.  It's often useful to combine multidimensional scaling (MDS) with
% a glyph plot.  To illustrate, we'll first select all cars from 1977, and
% use the |zscore| function to standardize each of the five variables to
% have zero mean and unit variance.  Then we'll compute the Euclidean
% distances among those standardized observations as a measure of
% dissimilarity.  This choice might be too simplistic in a real
% application, but serves here for purposes of illustration.
models77 = find((Model_Year==77));
dissimilarity = pdist(zscore(X(models77,:)));

%%
% Finally, we use |mdscale| to create a set of locations in two dimensions
% whose interpoint distances approximate the dissimilarities among the
% original high-dimensional data, and plot the glyphs using those
% locations.  The distances in this 2D plot may only roughly reproduce the
% data, but for this type of plot, that's good enough.
Y = mdscale(dissimilarity,2);
glyphplot(X(models77,:), 'glyph','star', 'centers',Y, ...
          'varLabels',varNames, 'obslabels',Model(models77,:), 'radius',.5);
title('1977 Model Year');

%%
% In this plot, we've used MDS as dimension reduction method, to create a
% 2D plot.  Normally that would mean a loss of information, but by plotting
% the glyphs, we have incorporated all of the high-dimensional information
% in the data.  The purpose of using MDS is to impose some regularity to
% the variation in the data, so that patterns among the glyphs are easier
% to see.

%%
% Just as with the previous plot, interactive exploration would be possible
% in a live figure window.

%%
% Another type of glyph is the Chernoff face.  This glyph encodes the data
% values for each observation into facial features, such as the size of the
% face, the shape of the face, position of the eyes, etc.
glyphplot(X(models77,:), 'glyph','face', 'centers',Y, ...
          'varLabels',varNames, 'obslabels',Model(models77,:));
title('1977 Model Year');

%%
% Here, the two most apparent features, face size and relative forehead/jaw
% size, encode MPG and acceleration, while the forehead and jaw shape
% encode displacement and weight.  Width between eyes encodes horsepower.
% It's notable that there are few faces with wide foreheads and narrow
% jaws, or vice-versa, indicating positive linear correlation between the
% variables displacement and weight.  That's also what we saw in the
% scatterplot matrix.
%
% The correspondence of features to variables determines what relationships
% are easiest to see, and |glyphplot| allows the choice to be changed easily.


%%
close


displayEndOfDemoMessage(mfilename)
##### SOURCE END #####
--></body></html>