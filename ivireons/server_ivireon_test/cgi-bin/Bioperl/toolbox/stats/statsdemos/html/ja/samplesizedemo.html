
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!-- This HTML was auto-generated from MATLAB code. To make changes, update the MATLAB code and republish this document.       --><title>サンプル サイズの選択</title><meta name="generator" content="MATLAB 7.11"><link rel="schema.DC" href="../http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2010-05-26"><meta name="DC.source" content="samplesizedemo.m"><link rel="stylesheet" type="text/css" href="../../../../matlab/demos/private/style.css"></head><body><div class="header"><div class="left"><a href="matlab:edit samplesizedemo">エディターで samplesizedemo.m を開く</a></div><div class="right"><a href="matlab:echodemo samplesizedemo">コマンド ウィンドウで実行</a></div></div><div class="content"><h1>サンプル サイズの選択</h1><!--introduction--><p>「 ... にはどれくらいのサンプルが必要ですか。」これは、統計作業でよく聞かれる質問です。Statistics Toolbox™ には、この質問の答えを得るのに役立つ <tt>sampsizepwr</tt> という関数が含まれています。</p><p>このデモでは、単純な問題に対するサンプル サイズの計算を示した後、関数 <tt>sampsizepwr</tt> を使用して、2 つのより現実的な問題に対してパワーとサンプル サイズを計算する方法を示します。最後に、関数 <tt>sampsizepwr</tt> がサポートしていないテストに対し、Statistics Toolbox 関数を使用して必要なサンプル サイズを計算する方法を示します。</p><!--/introduction--><h2>目次</h2><div><ul><li><a href="#1">既知の標準偏差を使用した正規平均の片側検定</a></li><li><a href="#7">不明な標準偏差を使用した正規平均の両側検定</a></li><li><a href="#13">比率の検定</a></li><li><a href="#19">相関の検定</a></li><li><a href="#23">まとめ</a></li></ul></div><h2>既知の標準偏差を使用した正規平均の片側検定<a name="1"></a></h2><p>概念を紹介するために、非現実的な単純な例を使用して、平均を検定し、標準偏差を確認してみましょう。データは連続しており、 正規分布を使用してモデル化できます。ここではサンプル サイズ N を判断し、100 の平均と 110 の平均とを区別できるようにする必要があります。標準偏差は 20 であることがわかっています。</p><p>統計検定を実施するとき、通常は<b>対立仮説</b>に対して<b>帰無仮説</b>を検定します。検定統計値 T を求め、帰無仮説のもとでその分布を確認します。たとえば帰無仮説が真の場合の発生確率が 5% 未満であるなどの異常な値が見つかった場合は、対立仮説を優先して帰無仮説を棄却します (5% の確率は、検定の<b>有意水準</b>と呼ばれます)。値が異常でない場合、帰無仮説は棄却しません。</p><p>この場合、検定統計値 T はサンプル平均です。帰無仮説のもとでは、平均は 100 で、標準偏差は 20/sqrt(N) です。まず、N=16 の固定サンプル サイズを見てみましょう。Tが影の領域、つまり分布の上裾にある場合は、帰無仮説を棄却します。T が下裾にある場合には棄却しないため、これは片側検定になります。この影の領域のカットオフは、平均より上の 1.6 標準偏差になります。</p><pre class="codeinput">rand(<span class="string">'state'</span>,0); randn(<span class="string">'state'</span>,0);
mu0 = 100; sig = 20; N = 16; alpha = 0.05; conf = 1-alpha;
cutoff = norminv(conf, mu0, sig/sqrt(N));
x = [linspace(90,cutoff), linspace(cutoff,127)];
y = normpdf(x,mu0,sig/sqrt(N));
h1 = plot(x,y);
xhi = [cutoff, x(x&gt;=cutoff)]; yhi = [0, y(x&gt;=cutoff)];
patch(xhi,yhi,<span class="string">'b'</span>);
title(<span class="string">'Distribution of sample mean, N=16'</span>);
xlabel(<span class="string">'Sample mean'</span>); ylabel(<span class="string">'Density'</span>);
text(96,.01,sprintf(<span class="string">'Reject if mean&gt;%.4g\nProb = 0.05'</span>,cutoff),<span class="string">'Color'</span>,<span class="string">'b'</span>);
</pre><img vspace="5" hspace="5" src="../samplesizedemo_01.png" alt=""> <p>これは、帰無仮説のものでの T の動作を示していますが、対立仮説のもとではどうでしょうか。対立分布の平均は、赤の曲線で示されるように 110 です。</p><pre class="codeinput">mu1 = 110;
y2 = normpdf(x,mu1,sig/sqrt(N));
h2 = line(x,y2,<span class="string">'Color'</span>,<span class="string">'r'</span>);
yhi = [0, y2(x&gt;=cutoff)];
patch(xhi,yhi,<span class="string">'r'</span>,<span class="string">'FaceAlpha'</span>,0.25);
P = 1 - normcdf(cutoff,mu1,sig/sqrt(N));
text(115,.06,sprintf(<span class="string">'Reject if T&gt;%.4g\nProb = %.2g'</span>,cutoff,P),<span class="string">'Color'</span>,[1 0 0]);
legend([h1 h2],<span class="string">'Null hypothesis'</span>,<span class="string">'Alternative hypothesis'</span>);
</pre><img vspace="5" hspace="5" src="../samplesizedemo_02.png" alt=""> <p>対立仮説が真の場合に帰無仮説を棄却する確率は高くなっています。これは、望むとおりの現象です。確率密度関数 (pdf) ではなく累積分布関数 (cdf) を見てみると、さらにわかりやすくなります。確率は、面積を計算しなくても、グラフから直接読み取ることができます。</p><pre class="codeinput">ynull = normcdf(x,mu0,sig/sqrt(N));
yalt = normcdf(x,mu1,sig/sqrt(N));
h12 = plot(x,ynull,<span class="string">'b-'</span>,x,yalt,<span class="string">'r-'</span>);
zval = norminv(conf);
cutoff = mu0 + zval * sig / sqrt(N);
line([90,cutoff,cutoff],[conf, conf, 0],<span class="string">'LineStyle'</span>,<span class="string">':'</span>);
msg = sprintf(<span class="string">' Cutoff = 100 + %.2g \\times 20 / \\surd{n}'</span>,zval);
text(cutoff,.15,msg,<span class="string">'Color'</span>,<span class="string">'b'</span>);
text(min(x),conf,sprintf(<span class="string">'   %g%% test'</span>,100*alpha),<span class="string">'Color'</span>,<span class="string">'b'</span>,<span class="keyword">...</span>
                         <span class="string">'verticalalignment'</span>,<span class="string">'top'</span>)
palt = normcdf(cutoff,mu1,sig/sqrt(N));
line([90,cutoff],[palt,palt],<span class="string">'Color'</span>,<span class="string">'r'</span>,<span class="string">'LineStyle'</span>,<span class="string">':'</span>);
text(91,palt+.02,sprintf(<span class="string">' Power is 1-%.2g = %.2g'</span>,palt,1-palt),<span class="string">'Color'</span>,[1 0 0]);
legend(h12,<span class="string">'Null hypothesis'</span>,<span class="string">'Alternative hypothesis'</span>);
</pre><img vspace="5" hspace="5" src="../samplesizedemo_03.png" alt=""> <p>このグラフは、N=16 である場合に 2 つの異なる mu 値に対して有意な統計値を得る (帰無仮説を棄却する) 確率を示しています。</p><p><b>べき乗関数</b>は、対立仮説が真の場合に帰無仮説を棄却する確率として定義されています。これは、対立仮説の値とサンプル サイズに依存します。パワー (cdf より 1 を差し引いたもの) を N の関数とし、対立仮説値は 110 に固定してグラフを作成します。 80% のパワーを実現するために、N を選択します。グラフは、約 N=25 が必要であることを示しています。</p><pre class="codeinput">DesiredPower = 0.80;
Nvec = 1:30;
cutoff = mu0 + norminv(conf)*sig./sqrt(Nvec);
power = 1 - normcdf(cutoff, mu1, sig./sqrt(Nvec));
plot(Nvec,power,<span class="string">'bo-'</span>,[0 30],[DesiredPower DesiredPower],<span class="string">'k:'</span>);
xlabel(<span class="string">'N = sample size'</span>); ylabel(<span class="string">'Power'</span>)
title(<span class="string">'Power function for the alternative:\mu = 110'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_04.png" alt=""> <p>この非常に単純な例では、必要な値を直接計算して 80% のパワーを得るための公式があります。</p><pre class="codeinput">mudiff = (mu1 - mu0) / sig;
N80 = ceil(((norminv(1-DesiredPower)-norminv(conf)) / mudiff)^2)
</pre><pre class="codeoutput">
N80 =

    25

</pre><p>これが機能することを確認するために、モンテ カルロ シミュレーションを行って、平均が 100 の帰無仮説と、平均が 110 の対立仮説のもとで、サイズが 25 のサンプルを 400 個を生成してみましょう。平均が 100 であるかどうかを確認するために各サンプルを検定する場合は、約 5% の最初のグループと約 80% の 2 番目のグループが有意になる必要があります。</p><pre class="codeinput">nsamples = 400; samplenum = 1:nsamples; N=25;
h0 = zeros(1,nsamples); h1 = h0;
<span class="keyword">for</span> j=1:nsamples
    Z0 = normrnd(mu0,sig,N,1);
    h0(j) = ztest(Z0,mu0,sig,alpha,<span class="string">'right'</span>);
    Z1 = normrnd(mu1,sig,N,1);
    h1(j) = ztest(Z1,mu0,sig,alpha,<span class="string">'right'</span>);
<span class="keyword">end</span>
p0 = cumsum(h0) ./ samplenum;
p1 = cumsum(h1) ./ samplenum;
plot(samplenum,p0,<span class="string">'b-'</span>,samplenum,p1,<span class="string">'r-'</span>)
xlabel(<span class="string">'Sample number'</span>); ylabel(<span class="string">'Proportion significant'</span>)
title(<span class="string">'Verification of power computation'</span>)
legend(<span class="string">'Null hypothesis'</span>,<span class="string">'Alternative hypothesis'</span>,<span class="string">'Location'</span>,<span class="string">'East'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_05.png" alt=""> <h2>不明な標準偏差を使用した正規平均の両側検定<a name="7"></a></h2><p>次に、標準偏差がわからない場合に、両側検定、つまり、サンプル平均が高すぎるか低すぎるかによって帰無仮説を棄却する検定を実施したいとします。</p><p>検定の統計値は t 統計値、つまり、サンプル平均と検定対象の平均の差を平均の標準誤差で割ったものです。帰無仮説のもとでは、これは N-1 の自由度を持つスチューデントの t 分布を含みます。対立仮説のもとでは、分布は、真の平均と検定対象の平均の正規化された差に等しい非心度パラメーターを持つ非心 t 分布になります。</p><p>この両側検定に対しては、帰無仮説のもとで、両方の裾に等しい 5% の誤差確率を割り当て、検定統計値がどちらかの方向において極端すぎる場合に棄却する必要があります。また、どの対立仮説のもとでも両方の裾を考慮する必要があります。</p><pre class="codeinput">N = 16; df = N-1; alpha = 0.05; conf = 1-alpha;
cutoff1 = tinv(alpha/2,df); cutoff2 = tinv(1-alpha/2,df);
x = [linspace(-5,cutoff1), linspace(cutoff1,cutoff2),linspace(cutoff2,5)];
y = tpdf(x,df);
h1 = plot(x,y);
xlo = [x(x&lt;=cutoff1),cutoff1]; ylo = [y(x&lt;=cutoff1),0];
xhi = [cutoff2,x(x&gt;=cutoff2)]; yhi = [0, y(x&gt;=cutoff2)];
patch(xlo,ylo,<span class="string">'b'</span>); patch(xhi,yhi,<span class="string">'b'</span>);
title(<span class="string">'Distribution of t statistic, N=16'</span>);
xlabel(<span class="string">'t'</span>); ylabel(<span class="string">'Density'</span>);
text(2.5,.05,sprintf(<span class="string">'Reject if t&gt;%.4g\nProb = 0.025'</span>,cutoff2),<span class="string">'Color'</span>,<span class="string">'b'</span>);
text(-4.5,.05,sprintf(<span class="string">'Reject if t&lt;%.4g\nProb = 0.025'</span>,cutoff1),<span class="string">'Color'</span>,<span class="string">'b'</span>);
</pre><img vspace="5" hspace="5" src="../samplesizedemo_06.png" alt=""> <p>帰無仮説のみのもとでのべき乗関数と、mu の単一の対立仮説値を調べる代わりに、それを mu の関数として見ることができます。パワーは、mu がどちらかの方向において帰無仮説から遠ざかるにつれて増加します。パワーを計算するには、関数 <tt>sampsizepwr</tt> を使用できます。パワーの計算には、標準偏差の値を指定する必要があります。これは約 20 になることが予想されます。サンプル サイズ N=16 のべき乗関数の図は次のようになります。</p><pre class="codeinput">N = 16;
x = linspace(90,127);
power = sampsizepwr(<span class="string">'t'</span>,[100 20],x,[],N);
plot(x,power);
xlabel(<span class="string">'True mean'</span>)
ylabel(<span class="string">'Power'</span>)
title(<span class="string">'Power function for N=16'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_07.png" alt=""> <p>平均が 110 のときにパワーが 80% になる必要があります。このグラフによると、N=16 のサンプル サイズではパワーは 50% 未満になります。どのサンプル サイズを使用すれば目的のパワーが得られるのでしょうか。</p><pre class="codeinput">N = sampsizepwr(<span class="string">'t'</span>,[100 20],110,0.8)
</pre><pre class="codeoutput">
N =

    34

</pre><p>約 34 のサンプル サイズが必要です。前の例と比較すると、観測を 9 個追加して両側検定を行い、不明な真の標準偏差を補う必要があります。</p><p>べき乗関数のプロットは、さまざまな N の値に対して作成できます。</p><pre class="codeinput">Nvec = 02:40:00;
power = sampsizepwr(<span class="string">'t'</span>,[100 20],110,[],Nvec);
plot(Nvec,power,<span class="string">'bo-'</span>,[0 40],[DesiredPower DesiredPower],<span class="string">'k:'</span>);
xlabel(<span class="string">'N = sample size'</span>)
ylabel(<span class="string">'Power'</span>)
title(<span class="string">'Power function for the alternative:\mu = 110'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_08.png" alt=""> <p>そして、前回と同じようなシミュレーションを実行し、必要なパワーが得られるかどうかを確認できます。</p><pre class="codeinput">nsamples = 400; samplenum = 1:nsamples; N = 34;
h0 = zeros(1,nsamples); h1 = h0;
<span class="keyword">for</span> j=1:nsamples
    Z0 = normrnd(mu0,sig,N,1);
    h0(j) = ttest(Z0,mu0,alpha);
    Z1 = normrnd(mu1,sig,N,1);
    h1(j) = ttest(Z1,mu0,alpha);
<span class="keyword">end</span>
p0 = cumsum(h0) ./ samplenum;
p1 = cumsum(h1) ./ samplenum;
plot(samplenum,p0,<span class="string">'b-'</span>,samplenum,p1,<span class="string">'r-'</span>)
xlabel(<span class="string">'Sample number'</span>); ylabel(<span class="string">'Proportion significant'</span>)
title(<span class="string">'Verification of power computation'</span>)
legend(<span class="string">'Null hypothesis'</span>,<span class="string">'Alternative hypothesis'</span>,<span class="string">'Location'</span>,<span class="string">'East'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_09.png" alt=""> <p>50 のサンプル サイズを用意する余裕があるとします。対立仮説値 mu=110 を検出するためのパワーは 80% より大きくなることが予想されます。80% のパワーを維持する場合は、どのような対立仮説を検出できるでしょうか。</p><pre class="codeinput">mu1 = sampsizepwr(<span class="string">'t'</span>,[100 20],[],.8,50)
</pre><pre class="codeoutput">
mu1 =

  108.0837

</pre><h2>比率の検定<a name="13"></a></h2><p>次に、2 つの比率を区別するために必要なサンプル サイズを判断する問題を考えましょう。約 30% の人々が候補者を支持している人口をサンプリングする場合において、この値を 33% とは区別できるだけの十分な数の人々をサンプリングしたいとします。</p><p>ここでの観念は、前回と同じです。ここでは、サンプル数を検定統計数として使用できます。この数には二項分布が含まれています。任意のサンプル サイズ N に対して、帰無仮説 P=0.30 を棄却するためのカットオフを計算できます。たとえば N=100 の場合は、サンプル数が以下のように計算されたカットオフ値よりも大きい場合に帰無仮説を棄却します。</p><pre class="codeinput">N = 100; alpha = 0.05; p0 = 0.30; p1 = 0.33;
cutoff = binoinv(1-alpha, N, p0)
</pre><pre class="codeoutput">
cutoff =

    38

</pre><p>二項分布は離散分布であるため、複雑さが伴います。カットオフ値を超過する確率は、正確に 5% ではありません。</p><pre class="codeinput">1 - binocdf(cutoff, N, p0)
</pre><pre class="codeoutput">
ans =

    0.0340

</pre><p>ここでも、サンプル サイズの範囲における対立仮説値 P=0.33 に対するパワーを計算しましょう。ここでは 30% より大きい対立仮説値のみに注目する必要があるため、片側 (右裾) 検定を使用します。</p><pre class="codeinput">Nvec = 50:50:2000;
power = sampsizepwr(<span class="string">'p'</span>,p0,p1,[],Nvec,<span class="string">'tail'</span>,<span class="string">'right'</span>);
plot(Nvec,power,<span class="string">'bo-'</span>,[0 2000],[DesiredPower DesiredPower],<span class="string">'k:'</span>);
xlabel(<span class="string">'N = sample size'</span>)
ylabel(<span class="string">'Power'</span>)
title(<span class="string">'Power function for the alternative:p = 0.33'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_10.png" alt=""> <p>関数 <tt>sampsizepwr</tt> を使用して、80% のパワーに必要なサンプル サイズを要求します。</p><pre class="codeinput">approxN = sampsizepwr(<span class="string">'p'</span>,p0,p1,0.80,[],<span class="string">'tail'</span>,<span class="string">'right'</span>)
</pre><pre class="codeoutput">警告:Values N&gt;200 are approximate.Plotting the power as a function
of N may reveal lower N values that have the required power. 

approxN =

        1500

</pre><p>警告メッセージにより、回答は近似であることが伝えられます。異なるサンプル サイズに対してべき乗関数を見てみると、二項分布は離散であるため、関数は一般的に増加しますが、不規則であることがわかります。1470 ～ 1480 のサンプル サイズ範囲において、p=0.30 および p=0.33 の両方に対して帰無仮説を棄却する確率を見てみましょう。</p><pre class="codeinput">subplot(3,1,1);
Nvec = 1470:1480;
power = sampsizepwr(<span class="string">'p'</span>,p0,p1,[],Nvec,<span class="string">'tail'</span>,<span class="string">'right'</span>);
plot(Nvec,power,<span class="string">'ro-'</span>,[min(Nvec),max(Nvec)],[DesiredPower DesiredPower],<span class="string">'k:'</span>);
ylabel(sprintf(<span class="string">'Prob[T&gt;cutoff]\nif p=0.33'</span>))
set(gca,<span class="string">'xticklabel'</span>,<span class="string">''</span>)

subplot(3,1,2);
alf = sampsizepwr(<span class="string">'p'</span>,p0,p0,[],Nvec,<span class="string">'tail'</span>,<span class="string">'right'</span>);
plot(Nvec,alf,<span class="string">'bo-'</span>,[min(Nvec),max(Nvec)],[alpha alpha],<span class="string">'k:'</span>);
ylabel(sprintf(<span class="string">'Prob[T&gt;cutoff]\nif p=0.30'</span>))
set(gca,<span class="string">'xticklabel'</span>,<span class="string">''</span>)

subplot(3,1,3);
cutoff = binoinv(1-alpha, Nvec, p0);
plot(Nvec,cutoff,<span class="string">'go-'</span>);
xlabel(<span class="string">'N = sample size'</span>)
ylabel(<span class="string">'Cutoff'</span>)
</pre><img vspace="5" hspace="5" src="../samplesizedemo_11.png" alt=""> <p>このプロットは、べき乗関数の曲線 (上部のプロット) が不規則なだけでなく、一部のサンプル サイズで減少していることを示しています。これらのサンプル サイズでは、5% 以下の有意水準 (中央のプロット) を保持するためにカットオフ値 (下部のプロット) を増加する必要があります。この範囲内で、目的の 80% のパワーを提供するより小さいサンプル サイズを見つけることができます。</p><pre class="codeinput">min(Nvec(power&gt;=0.80))
</pre><pre class="codeoutput">
ans =

        1478

</pre><h2>相関の検定<a name="19"></a></h2><p>これまでに検討した例では、特定の有意レベルを達成するための検定統計値のカットオフを求め、対立仮説のもとでそのカットオフを超える確率を計算することができました。最後の例では、少し難しい問題を考えてみましょう。</p><p>2 つの変数 X および Y からのサンプルを使用する場合に、これらが相関していないか、あるいは相関が最高で 0.4 にも及ぶことがあるかを検査するために必要なサンプル サイズを知りたいとします。サンプルの相関の分布を t 分布に変換することで解を得ることは可能ですが、検定統計値の分布に対処できない問題においても使用できる方法を採用してみましょう。</p><p>任意のサンプル サイズに対してモンテ カルロ シミュレーションを使用すると、相関の検定に適したカットオフ値を判断できます。大きなシミュレーションを実行してこの値を正確に求めてみましょう。まず、25 のサンプル サイズから始めます。</p><pre class="codeinput">nsamples = 10000; N = 25; alpha = 0.05; conf = 1-alpha;
r = zeros(1,nsamples);
<span class="keyword">for</span> j=1:nsamples
    xy = normrnd(0,1,N,2);
    r(j) = corr(xy(:,1),xy(:,2));
<span class="keyword">end</span>
cutoff = quantile(r,conf)
</pre><pre class="codeoutput">
cutoff =

    0.3382

</pre><p>次に、対立仮説のもとでサンプルを生成し、検定のパワーを推定します。</p><pre class="codeinput">nsamples = 1000; mu = [0; 0]; sig = [1 0.4; 0.4 1];
r = zeros(1,nsamples);
<span class="keyword">for</span> j=1:nsamples
    xy = mvnrnd(mu,sig,N);
    r(j) = corr(xy(:,1),xy(:,2));
<span class="keyword">end</span>
[power,powerci] = binofit(sum(r&gt;cutoff),nsamples)
</pre><pre class="codeoutput">
power =

    0.6490


powerci =

    0.6185    0.6786

</pre><p>パワーは 65% であると推定し、真の値が 62% ～ 68% の範囲内にある信頼率は 95% とします。80% のパワーを得るには、より大きなサンプル サイズが必要です。N を 50 に増加し、このサンプル サイズのカットオフ値を推定して、パワー シミュレーションを繰り返すことができます。</p><pre class="codeinput">nsamples = 10000; N = 50; alpha = 0.05; conf = 1-alpha;
r = zeros(1,nsamples);
<span class="keyword">for</span> j=1:nsamples
    xy = normrnd(0,1,N,2);
    r(j) = corr(xy(:,1),xy(:,2));
<span class="keyword">end</span>
cutoff = quantile(r,conf)

nsamples = 1000; mu = [0; 0]; sig = [1 0.4; 0.4 1];
r = zeros(1,nsamples);
<span class="keyword">for</span> j=1:nsamples
    xy = mvnrnd(mu,sig,N);
    r(j) = corr(xy(:,1),xy(:,2));
<span class="keyword">end</span>
[power,powerci] = binofit(sum(r&gt;cutoff),nsamples)
</pre><pre class="codeoutput">
cutoff =

    0.2387


power =

    0.8990


powerci =

    0.8786    0.9170

</pre><p>このサンプル サイズでは、80% の目標を上回るパワーが得られます。このようにして試行錯誤を繰り返すと、ここでの要件を満たす 50 未満のサンプル サイズを見つけることができます。</p><h2>まとめ<a name="23"></a></h2><p>Statistics Toolbox の確率関数を使用すると、仮説検定における目的のパワー レベルの実現に必要なサンプル サイズを判断できます。問題によっては、サンプル サイズを直接計算できる場合と、正しい値が見つかるまでサンプル サイズの範囲を探し求める必要が生じる場合があります。乱数発生器は、目的のパワーが満たされているかどうかを確認するのに役立ちます。また、対立条件下で特定の検定のパワーを調べるためにも使用できます。</p><p class="footer">Copyright 2004-2007 The MathWorks, Inc.<br>Published with MATLAB&reg; 7.11</p><p class="footer" id="trademarks">MATLAB and Simulink are registered trademarks of The MathWorks, Inc.  Please see <a href="http://www.mathworks.com/trademarks">www.mathworks.com/trademarks</a> for a list of other trademarks owned by The MathWorks, Inc.  Other product or brand names are trademarks or registered trademarks of their respective owners.</p></div><!-- ##### SOURCE BEGIN ##### %% Selecting a Sample Size % "How many samples do I need to ...?"  This is a common question in % statistics.  The Statistics Toolbox(TM) has a function called |sampsizepwr| % that can help answer that question. % % This demonstration illustrates sample size calculations for a simple % problem, then shows how to use the |sampsizepwr| function to compute % power and sample size for two more realistic problems.  Finally, it % illustrates the use of Statistics Toolbox functions to compute the % required sample size for a test that the |sampsizepwr| function does not % support.  %   Copyright 2004-2007 The MathWorks, Inc. %   $Revision: 1.1.4.2.2.1 $  $Date: 2010/07/29 21:29:29 $  %% Testing a Normal Mean with Known Standard Deviation, One-Sided % Just to introduce some concepts, let's consider an unrealistically simple % example where we want to test a mean and we know the standard deviation. % Our data are continuous, and can be modeled with the normal distribution. % We need to determine a sample size N so that we can distinguish between a % mean of 100 and a mean of 110. We know the standard deviation is 20. % % When we carry out a statistical test, we generally test a *null % hypothesis* against an *alternative hypothesis*.  We find a test % statistic T, and look at its distribution under the null hypothesis.  If % we observe an unusual value, say one that has less than 5% chance of % happening if the null hypothesis is true, then we reject the null % hypothesis in favor of the alternative.  (The 5% probability is known as % the *significance level* of the test.)  If the value is not unusual, we do % not reject the null hypothesis. % % In this case the test statistic T is the sample mean.  Under the null % hypothesis it has a mean of 100 and a standard deviation of 20/sqrt(N). % First let's look at a fixed sample size, say N=16.  We will reject the % null hypothesis if T is in the shaded region, which is the upper tail of % its distribution.  That makes this a one-sided test, since we will not % reject if T is in the lower tail.  The cutoff for this shaded region is % 1.6 standard deviations above the mean.  rand('state',0); randn('state',0); mu0 = 100; sig = 20; N = 16; alpha = 0.05; conf = 1-alpha; cutoff = norminv(conf, mu0, sig/sqrt(N)); x = [linspace(90,cutoff), linspace(cutoff,127)]; y = normpdf(x,mu0,sig/sqrt(N)); h1 = plot(x,y); xhi = [cutoff, x(x>=cutoff)]; yhi = [0, y(x>=cutoff)]; patch(xhi,yhi,'b'); title('Distribution of sample mean, N=16'); xlabel('Sample mean'); ylabel('Density'); text(96,.01,sprintf('Reject if mean>%.4g\nProb = 0.05',cutoff),'Color','b');   %% % This is how T behaves under the null hypothesis, but what about under an % alternative?  Our alternative distribution has a mean of 110, as % represented by the red curve. mu1 = 110; y2 = normpdf(x,mu1,sig/sqrt(N)); h2 = line(x,y2,'Color','r'); yhi = [0, y2(x>=cutoff)]; patch(xhi,yhi,'r','FaceAlpha',0.25); P = 1 - normcdf(cutoff,mu1,sig/sqrt(N)); text(115,.06,sprintf('Reject if T>%.4g\nProb = %.2g',cutoff,P),'Color',[1 0 0]); legend([h1 h2],'Null hypothesis','Alternative hypothesis');  %% % There is a larger chance of rejecting the null hypothesis if the % alternative is true.  This is just what we want.  It's easier to % visualize if we look at the cumulative distribution function (cdf) % instead of the density (pdf).  We can read probabilities directly from % this graph, instead of having to compute areas.  ynull = normcdf(x,mu0,sig/sqrt(N)); yalt = normcdf(x,mu1,sig/sqrt(N)); h12 = plot(x,ynull,'b-',x,yalt,'r-'); zval = norminv(conf); cutoff = mu0 + zval * sig / sqrt(N); line([90,cutoff,cutoff],[conf, conf, 0],'LineStyle',':'); msg = sprintf(' Cutoff = 100 + %.2g \\times 20 / \\surd{n}',zval); text(cutoff,.15,msg,'Color','b'); text(min(x),conf,sprintf('   %g%% test',100*alpha),'Color','b',...                          'verticalalignment','top') palt = normcdf(cutoff,mu1,sig/sqrt(N)); line([90,cutoff],[palt,palt],'Color','r','LineStyle',':'); text(91,palt+.02,sprintf(' Power is 1-%.2g = %.2g',palt,1-palt),'Color',[1 0 0]); legend(h12,'Null hypothesis','Alternative hypothesis');  %% % This graph shows the probability of getting a significant statistic % (rejecting the null hypothesis) for two different mu values when N=16. % % The *power function* is defined as the probability of rejecting the null % hypothesis when the alternative is true.  It depends on the value of the % alternative and on the sample size.  We'll graph the power (which is one % minus the cdf) as a function of N, fixing the alternative at 110.  We'll % select N to achieve a power of 80%.  The graph shows that we need about N=25.  DesiredPower = 0.80; Nvec = 1:30; cutoff = mu0 + norminv(conf)*sig./sqrt(Nvec); power = 1 - normcdf(cutoff, mu1, sig./sqrt(Nvec)); plot(Nvec,power,'bo-',[0 30],[DesiredPower DesiredPower],'k:'); xlabel('N = sample size'); ylabel('Power') title('Power function for the alternative: \mu = 110')   %% % In this overly simple example there is a formula to compute the required % value directly to get a power of 80%: mudiff = (mu1 - mu0) / sig; N80 = ceil(((norminv(1-DesiredPower)-norminv(conf)) / mudiff)^2)  %% % To verify that this works, let's do a Monte Carlo simulation and generate % 400 samples of size 25 both  under the null hypothesis with mean 100, and % under the alternative hypothesis with mean 110.  If we test each sample % to see if its mean is 100, we should expect about 5% of the first group % and 80% of the second group to be significant. nsamples = 400; samplenum = 1:nsamples; N=25; h0 = zeros(1,nsamples); h1 = h0; for j=1:nsamples     Z0 = normrnd(mu0,sig,N,1);     h0(j) = ztest(Z0,mu0,sig,alpha,'right');     Z1 = normrnd(mu1,sig,N,1);     h1(j) = ztest(Z1,mu0,sig,alpha,'right'); end p0 = cumsum(h0) ./ samplenum; p1 = cumsum(h1) ./ samplenum; plot(samplenum,p0,'b-',samplenum,p1,'r-') xlabel('Sample number'); ylabel('Proportion significant') title('Verification of power computation') legend('Null hypothesis','Alternative hypothesis','Location','East')  %% Testing a Normal Mean with Unknown Standard Deviation, Two-Sided % Now let's suppose we don't know the standard deviation, and we want to % perform a two-sided test, that is, one that rejects the null hypothesis % whether the sample mean is too high or too low. % % The test statistic is a t statistic, which is the difference between the % sample mean and the mean being tested, divided by the standard error of % the mean.  Under the null hypothesis, this has Student's t distribution % with N-1 degrees of freedom.  Under the alternative hypothesis, the % distribution is a noncentral t distribution with a noncentrality % parameter equal to the normalized difference between the true mean and % the mean being tested. % % For this two-sided test we have to allocate the 5% chance of an error % under the null hypothesis equally to both tails, and reject if the test % statistic is too extreme in either direction.  We also have to consider % both tails under any alternative.  N = 16; df = N-1; alpha = 0.05; conf = 1-alpha; cutoff1 = tinv(alpha/2,df); cutoff2 = tinv(1-alpha/2,df); x = [linspace(-5,cutoff1), linspace(cutoff1,cutoff2),linspace(cutoff2,5)]; y = tpdf(x,df); h1 = plot(x,y); xlo = [x(x<=cutoff1),cutoff1]; ylo = [y(x<=cutoff1),0]; xhi = [cutoff2,x(x>=cutoff2)]; yhi = [0, y(x>=cutoff2)]; patch(xlo,ylo,'b'); patch(xhi,yhi,'b'); title('Distribution of t statistic, N=16'); xlabel('t'); ylabel('Density'); text(2.5,.05,sprintf('Reject if t>%.4g\nProb = 0.025',cutoff2),'Color','b'); text(-4.5,.05,sprintf('Reject if t<%.4g\nProb = 0.025',cutoff1),'Color','b');   %% % Instead of examining the power function just under the null hypothesis % and a single alternative value of mu, we can look at it as a function of % mu.  The power increases as mu moves away from the null hypothesis value % in either direction.  We can use the |sampsizepwr| function to compute % the power.  For a power calculation we need to specify a value for the % standard deviation, which we suspect will be roughly 20.  Here's a % picture of the power function for a sample size N=16.  N = 16; x = linspace(90,127); power = sampsizepwr('t',[100 20],x,[],N); plot(x,power); xlabel('True mean') ylabel('Power') title('Power function for N=16')  %% % We want a power of 80% when the mean is 110.  According to this graph, % our power is less than 50% with a sample size of N=16.  What sample size % will give the power we want?  N = sampsizepwr('t',[100 20],110,0.8)  %% % We need a sample size of about 34. Compared with the previous example, we % need to take nine additional observations to allow a two-sided test and % to make up for not knowing the true standard deviation. % % We can make a plot of the power function for various values of N. Nvec = 2:40; power = sampsizepwr('t',[100 20],110,[],Nvec); plot(Nvec,power,'bo-',[0 40],[DesiredPower DesiredPower],'k:'); xlabel('N = sample size') ylabel('Power') title('Power function for the alternative: \mu = 110')  %% % And we can do a simulation similar to the earlier one to verify that we % get the power we need.  nsamples = 400; samplenum = 1:nsamples; N = 34; h0 = zeros(1,nsamples); h1 = h0; for j=1:nsamples     Z0 = normrnd(mu0,sig,N,1);     h0(j) = ttest(Z0,mu0,alpha);     Z1 = normrnd(mu1,sig,N,1);     h1(j) = ttest(Z1,mu0,alpha); end p0 = cumsum(h0) ./ samplenum; p1 = cumsum(h1) ./ samplenum; plot(samplenum,p0,'b-',samplenum,p1,'r-') xlabel('Sample number'); ylabel('Proportion significant') title('Verification of power computation') legend('Null hypothesis','Alternative hypothesis','Location','East')  %% % Suppose we could afford to take a sample size of 50.  Presumably our % power for detecting the alternative value mu=110 would be larger than % 80%.  If we maintain the power at 80%, what alternative could we % detect? mu1 = sampsizepwr('t',[100 20],[],.8,50)  %% Testing a Proportion % Now let's turn to the problem of determining the sample size needed to % distinguish between two proportions.  Suppose that we are sampling a % population in which about 30% favor some candidate, and we want to sample % enough people so we can distinguish this value from 33%. % % The idea here is the same as before.  Here we can use the sample count as % our test statistic.  This count has a binomial distribution.  For any % sample size N we can compute the cutoff for rejecting the null hypothesis % P=0.30.  For N=100, for instance, we would reject the null hypothesis if % the sample count is larger than a cutoff value computed as follows:  N = 100; alpha = 0.05; p0 = 0.30; p1 = 0.33; cutoff = binoinv(1-alpha, N, p0)  %% % A complication with the binomial distribution comes because it is % discrete.  The probability of exceeding the cutoff value is not exactly % 5%:  1 - binocdf(cutoff, N, p0)  %% % Once again, let's compute the power against the alternative P=0.33 for a % range of sample sizes.  We'll use a one-sided (right-tailed) test because % we're interested only in alternative values greater than 30%.  Nvec = 50:50:2000; power = sampsizepwr('p',p0,p1,[],Nvec,'tail','right'); plot(Nvec,power,'bo-',[0 2000],[DesiredPower DesiredPower],'k:'); xlabel('N = sample size') ylabel('Power') title('Power function for the alternative: p = 0.33')  %% % We can use the |sampsizepwr| function to request the sample size required % for a power of 80%.  approxN = sampsizepwr('p',p0,p1,0.80,[],'tail','right')  %% % A warning message informs us that the answer is just approximate.  If we % look at the power function for different sample sizes, we can see that % the function is generally increasing, but irregular because the binomial % distribution is discrete. Let's look at the probability of rejecting the % null hypothesis for both p=0.30 and p=0.33 in the range of samples sizes % from 1470 to 1480.  subplot(3,1,1); Nvec = 1470:1480; power = sampsizepwr('p',p0,p1,[],Nvec,'tail','right'); plot(Nvec,power,'ro-',[min(Nvec),max(Nvec)],[DesiredPower DesiredPower],'k:'); ylabel(sprintf('Prob[T>cutoff]\nif p=0.33')) set(gca,'xticklabel','')  subplot(3,1,2); alf = sampsizepwr('p',p0,p0,[],Nvec,'tail','right'); plot(Nvec,alf,'bo-',[min(Nvec),max(Nvec)],[alpha alpha],'k:'); ylabel(sprintf('Prob[T>cutoff]\nif p=0.30')) set(gca,'xticklabel','')  subplot(3,1,3); cutoff = binoinv(1-alpha, Nvec, p0); plot(Nvec,cutoff,'go-'); xlabel('N = sample size') ylabel('Cutoff')  %% % This plot reveals that the power function curve (top plot) is not only % irregular, but also decreases at some sample sizes.  These are the % sample sizes for which it is necessary to increase the cutoff value % (bottom plot) in order to keep the significance level (middle plot) no % larger than 5%.  We can find a smaller sample size within this range % that gives the desired power of 80%:  min(Nvec(power>=0.80))  %% Testing a Correlation % In the examples we've considered so far, we were able to figure out the % cutoff for a test statistic to achieve a certain significance level, and % to calculate the probability of exceeding that cutoff under an % alternative hypothesis.  For our final example, let's consider a problem % where that is not so easy. % % Imagine we can take samples from two variables X and Y, and we want to % know what sample size we would need to test whether they are uncorrelated % versus the alternative that their correlation is as high as 0.4. % Although it is possible to work out the distribution of the sample % correlation by transforming it to a t distribution, let's use a method % that we can use even in problems where we can't work out the distribution % of the test statistic. % % For a given sample size, we can use Monte Carlo simulation to determine % an approximate cutoff value for a test of the correlation.  Let's do a % large simulation run so we can get this value accurately.  We'll start % with a sample size of 25.  nsamples = 10000; N = 25; alpha = 0.05; conf = 1-alpha; r = zeros(1,nsamples); for j=1:nsamples     xy = normrnd(0,1,N,2);     r(j) = corr(xy(:,1),xy(:,2)); end cutoff = quantile(r,conf)  %% % Then we can generate samples under the alternative hypothesis, and % estimate the power of the test.  nsamples = 1000; mu = [0; 0]; sig = [1 0.4; 0.4 1]; r = zeros(1,nsamples); for j=1:nsamples     xy = mvnrnd(mu,sig,N);     r(j) = corr(xy(:,1),xy(:,2)); end [power,powerci] = binofit(sum(r>cutoff),nsamples)  %% % We estimate the power to be 65%, and we have 95% confidence that the true % value is between 62% and 68%.  To get a power of 80%, we need a larger % sample size.  We might try increasing N to 50, estimating the cutoff % value for this sample size, and repeating the power simulation.  nsamples = 10000; N = 50; alpha = 0.05; conf = 1-alpha; r = zeros(1,nsamples); for j=1:nsamples     xy = normrnd(0,1,N,2);     r(j) = corr(xy(:,1),xy(:,2)); end cutoff = quantile(r,conf)  nsamples = 1000; mu = [0; 0]; sig = [1 0.4; 0.4 1]; r = zeros(1,nsamples); for j=1:nsamples     xy = mvnrnd(mu,sig,N);     r(j) = corr(xy(:,1),xy(:,2)); end [power,powerci] = binofit(sum(r>cutoff),nsamples)  %% % This sample size gives a power better than our target of 80%.  We could % continue experimenting this way, trying to find a sample size less than % 50 that would meet our requirements.  %% Conclusion % The probability functions in the Statistics Toolbox can be used to % determine the sample size required to achieve a desired level of power in % a hypothesis test.  In some problems the sample size can be compute % directly; in others it is necessary to search over a range of sample % sizes until the right value is found. Random number generators can help % verify that the desired power is met, and can also be used to study the % power of a specific test under alternative conditions.   displayEndOfDemoMessage(mfilename)  ##### SOURCE END ##### --></body></html>